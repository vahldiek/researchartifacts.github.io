---
title: "Contribute"
permalink: /about.html
---

## About This Project

This project celebrates and promotes artifact evaluation in computer science research by providing statistics and recognition for researchers who contribute high-quality, reproducible artifacts.

We do not conduct artifact evaluations ourselves. Instead, we collect and aggregate results published by:

- **[sysartifacts.github.io](https://sysartifacts.github.io)** — Artifact evaluation results for systems conferences
- **[secartifacts.github.io](https://secartifacts.github.io)** — Artifact evaluation results for security conferences

The conferences covered on this site depend on what these sources track. See the [Methodology]({{ '/methodology.html' | relative_url }}) page for details on data collection.

## Inspired By

- **[Systems Circus](https://nebelwelt.net/pubstats/)** — Publication statistics for systems conferences by Mathias Payer
- **[DBLP](https://dblp.org/)** — Comprehensive computer science bibliography

## Data Availability

All data and code are open source:

- **Analysis Scripts**: [github.com/researchartifacts/artifact_analysis](https://github.com/researchartifacts/artifact_analysis)
- **Website Source**: [github.com/researchartifacts/researchartifacts.github.io](https://github.com/researchartifacts/researchartifacts.github.io)
- **Raw Data**: Available in `/assets/data/` directory (JSON format)

## How to Contribute

We welcome contributions:

- **Report Issues**: Found incorrect data? [Open an issue](https://github.com/researchartifacts/artifact_analysis/issues)
- **Add Conferences**: Know of other conferences with artifact evaluation? Let us know.
- **Improve Scripts**: Make scraping more robust or add features
- **Suggest Analyses**: What other statistics would be interesting?

---

*Built with [Jekyll](https://jekyllrb.com/) and the [Minimal Mistakes](https://mmistakes.github.io/minimal-mistakes/) theme.*
